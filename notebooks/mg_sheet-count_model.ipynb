{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e086a3dd",
   "metadata": {},
   "source": [
    "# Counting Metal Sheets with CNN Methods -Part II- <a class='tocSkip'>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b60bb8",
   "metadata": {},
   "source": [
    "**Contributors**: Moritz Geiger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed3ec9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d648c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO, BytesIO\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4610ee3",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000d383",
   "metadata": {},
   "source": [
    "- Paper about counting from air (trees, cars): [https://arxiv.org/pdf/2102.04366v1.pdf](https://arxiv.org/pdf/2102.04366v1.pdf)\n",
    "- more info on regression based methods: [https://arxiv.org/pdf/2007.01899v2.pdf](https://arxiv.org/pdf/2007.01899v2.pdf)\n",
    "- basic model to count fingers: [https://analyticsindiamag.com/how-to-implement-cnn-model-to-count-fingers-and-distinguish-between-left-and-right-hand/](https://analyticsindiamag.com/how-to-implement-cnn-model-to-count-fingers-and-distinguish-between-left-and-right-hand/)\n",
    "- How neural networks work: [https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480](https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480)\n",
    "- load training dataset for rsoc: [https://github.com/gaoguangshuai/Counting-from-Sky-A-Large-scale-Dataset-for-Remote-Sensing-Object-Counting-and-A-Benchmark-Method](https://github.com/gaoguangshuai/Counting-from-Sky-A-Large-scale-Dataset-for-Remote-Sensing-Object-Counting-and-A-Benchmark-Method)\n",
    "- Guide for CNN with pytorch: [https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce](https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8e71d",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599e0eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../raw_data/finals/1_00mm_58_86_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_37_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_47_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_46_152_fin.jpg',\n",
       " '../raw_data/finals/0_75mm_6_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_60_78_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_52_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_7_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_30_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_10_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_22_110_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_49_96_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_4_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_27_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_15_-99_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_1_63_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_42_154_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_20_-99_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_2_59_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_61_92_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_3_60_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_6_61_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_17_23_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_41_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_31_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_51_98_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_9_84_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_43_159_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_12_58_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_38_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_36_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_48_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_31_105_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_18_75_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_26_36_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_49_103_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_20_21_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_50_97_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_54_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_7_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_1_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_24_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_28_80_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_23_36_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_35_56_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_1_124_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_5_120_fin.jpg',\n",
       " '../raw_data/finals/0_75mm_5_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_40_52_fin.jpg',\n",
       " '../raw_data/finals/1_0mm_3_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_33_74_fin.jpg',\n",
       " '../raw_data/finals/1_0mm_6_3_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_26_123_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_34_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_44_-99_fin.jpg',\n",
       " '../raw_data/finals/1_0mm_0_89_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_8_58_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_32_23_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_5_62_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_48_94_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_0_55_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_44_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_34_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_33_109_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_5_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_2_120_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_39_56_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_41_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_11_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_6_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_0_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_23_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_43_53_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_36_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_16_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_25_36_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_24_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_9_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_21_129_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_29_91_fin.jpg',\n",
       " '../raw_data/finals/0_75mm_0_175_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_15_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_50_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_4_120_fin.jpg',\n",
       " '../raw_data/finals/1_0mm_2_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_12_-99_fin.jpg',\n",
       " '../raw_data/finals/1_2mm_4_48_fin.jpg',\n",
       " '../raw_data/finals/0_75mm_1_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_46_51_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_25_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_6_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_55_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_47_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_37_-99_fin.jpg',\n",
       " '../raw_data/finals/0_75mm_3_159_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_19_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_22_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_0_109_fin.jpg',\n",
       " '../raw_data/finals/1_0mm_1_81_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_30_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_8_69_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_40_-99_fin.jpg',\n",
       " '../raw_data/finals/1_5mm_10_-99_fin.jpg',\n",
       " '../raw_data/finals/1_00mm_16_21_fin.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load all filenames\n",
    "newpath = '../raw_data/finals'\n",
    "final_imgs = [os.path.join(newpath, img) for img in os.listdir(newpath)]\n",
    "final_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e0d09",
   "metadata": {},
   "source": [
    "**Note**<br>\n",
    "The filenames have the following structure:<br>\n",
    "```[thickness]_[id]_[sheetcount/target]_[<fin>].jpg```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d424ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final dataset consists of \u001b[1m104\u001b[0m images. Some of which are not counted (\"-99\") due to blurryness. That might be of interest for further analysis.\n"
     ]
    }
   ],
   "source": [
    "print(f'The final dataset consists of \\033[1m{len(final_imgs)}\\033[0m images. Some of which are not counted (\"-99\") due to blurryness. That might be of interest for further analysis.')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45e472",
   "metadata": {},
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9fbf5",
   "metadata": {},
   "source": [
    "The images show amateur photographs of metal sheet stacks on pallets in a warehouse during daylight conditions. The data provided contains metal sheets of sizes 0.75mm to 1.5mm. The sheets are either perforated or expanded. The perforated sheets lie horizontally on top of each other. The expanded metal forms a wavy profile when stacked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d76451",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showcasing some img examples\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(15):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    plt.title(f'img_{i}', size=12)\n",
    "    plt.imshow(mpimg.imread(final_imgs[i]))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e4e92",
   "metadata": {},
   "source": [
    "## Image quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19927c7",
   "metadata": {},
   "source": [
    "As visible, some of the images are not usable due to blurryness wrong angles. They would add too much noise to the model and will be manually sorted out of the data set. The optimal image should show the sheet stack from the side with enough light to detect the contrast between the sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee78fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find img resolutions\n",
    "sizes = []\n",
    "for img in final_imgs:\n",
    "    if 'jpg' in img:\n",
    "        im = PIL.Image.open(img)\n",
    "        sizes.append(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all images have the same resolution\n",
    "print(f'The resolution of all images is: \\033[1m{sizes[0][0]}x{sizes[0][1]}px\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab75812",
   "metadata": {},
   "source": [
    "**Note**<br>\n",
    "Further compressing and grayscaling will be assessed in the model tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6f06e",
   "metadata": {},
   "source": [
    "## Target Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## turning data into DF\n",
    "img_dict = {'filepath':[],\n",
    "            'thickness':[],\n",
    "            'target':[],\n",
    "           }\n",
    "for img in final_imgs:\n",
    "    splt = img.split('_')\n",
    "    img_dict['filepath'].append(img)\n",
    "    img_dict['thickness'].append(f'{splt[-5].split(\"/\")[-1]}.{splt[-4]}')\n",
    "    img_dict['target'].append(splt[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add189e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_df = pd.DataFrame(img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df.sort_values(by='thickness', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14841aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ba14a4f",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b786c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress\n",
    "# sharpness\n",
    "# grayscale\n",
    "# zoom?\n",
    "# image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fe71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74708b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
